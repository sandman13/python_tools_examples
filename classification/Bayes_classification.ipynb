{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯是一个实用性很强的分类模型，朴素贝叶斯会单独考量每一维度特征被分类的条件概率，进而综合这些概率并对其所在的特征向量做出分类预测。\n",
    "对20类新闻文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#获取数据\n",
    "from  sklearn.datasets import fetch_20newsgroups\n",
    "news=fetch_20newsgroups(subset='all')   #需要即时从互联网下载数据\n",
    "print(len(news.data))\n",
    "print(news.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的大小： (14134,)\n",
      "测试集的大小： (4712,)\n"
     ]
    }
   ],
   "source": [
    "#划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(news.data,news.target,test_size=0.25,random_state=33)\n",
    "print(\"训练集的大小：\",y_train.shape)\n",
    "print(\"测试集的大小：\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 60066)\t1\n",
      "  (0, 104942)\t1\n",
      "  (0, 14433)\t1\n",
      "  (0, 22750)\t1\n",
      "  (0, 17937)\t1\n",
      "  (0, 35665)\t1\n",
      "  (0, 44232)\t1\n",
      "  (0, 16311)\t1\n",
      "  (0, 79874)\t1\n",
      "  (0, 132903)\t1\n",
      "  (0, 132665)\t1\n",
      "  (0, 140565)\t1\n",
      "  (0, 129553)\t1\n",
      "  (0, 47467)\t1\n",
      "  (0, 51298)\t1\n",
      "  (0, 87060)\t1\n",
      "  (0, 65719)\t2\n",
      "  (0, 89395)\t1\n",
      "  (0, 34760)\t1\n",
      "  (0, 148646)\t2\n",
      "  (0, 76791)\t1\n",
      "  (0, 109290)\t1\n",
      "  (0, 57011)\t1\n",
      "  (0, 96571)\t1\n",
      "  (0, 11905)\t1\n",
      "  :\t:\n",
      "  (0, 88624)\t1\n",
      "  (0, 54291)\t1\n",
      "  (0, 137926)\t1\n",
      "  (0, 127872)\t1\n",
      "  (0, 105052)\t1\n",
      "  (0, 105079)\t1\n",
      "  (0, 144786)\t1\n",
      "  (0, 56181)\t1\n",
      "  (0, 27541)\t1\n",
      "  (0, 9352)\t1\n",
      "  (0, 67665)\t1\n",
      "  (0, 35136)\t1\n",
      "  (0, 4447)\t2\n",
      "  (0, 99226)\t2\n",
      "  (0, 78632)\t2\n",
      "  (0, 91899)\t2\n",
      "  (0, 65921)\t1\n",
      "  (0, 128977)\t1\n",
      "  (0, 123300)\t1\n",
      "  (0, 122222)\t2\n",
      "  (0, 59188)\t3\n",
      "  (0, 105230)\t3\n",
      "  (0, 93010)\t4\n",
      "  (0, 122236)\t2\n",
      "  (0, 66520)\t1\n"
     ]
    }
   ],
   "source": [
    "#使用贝叶斯分类器对新闻文本数据进行类别预测\n",
    "#首先需要使用到一个将文本特征化的模块，CountVectorizer是属于常见的特征数值计算类，是一个文本特征提取方法。对于每一个训练文本，它只考虑每种词汇在该训练文本中出现的频率。\n",
    "#CountVectorizer会将文本中的词语转换为词频矩阵，它通过fit_transform函数计算各个词语出现的次数。\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vex=CountVectorizer()\n",
    "X_train=vex.fit_transform(X_train)\n",
    "X_test=vex.transform(X_test)\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型,导入朴素贝叶斯模型\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb=MultinomialNB()\n",
    "mnb.fit(X_train,y_train)\n",
    "y_predict=mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is : 0.8397707979626485\n",
      "the detailed evaluation is:                           precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.86      0.86       201\n",
      "           comp.graphics       0.59      0.86      0.70       250\n",
      " comp.os.ms-windows.misc       0.89      0.10      0.17       248\n",
      "comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240\n",
      "   comp.sys.mac.hardware       0.93      0.78      0.85       242\n",
      "          comp.windows.x       0.82      0.84      0.83       263\n",
      "            misc.forsale       0.91      0.70      0.79       257\n",
      "               rec.autos       0.89      0.89      0.89       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.98      0.91      0.95       251\n",
      "        rec.sport.hockey       0.93      0.99      0.96       233\n",
      "               sci.crypt       0.86      0.98      0.91       238\n",
      "         sci.electronics       0.85      0.88      0.86       249\n",
      "                 sci.med       0.92      0.94      0.93       245\n",
      "               sci.space       0.89      0.96      0.92       221\n",
      "  soc.religion.christian       0.78      0.96      0.86       232\n",
      "      talk.politics.guns       0.88      0.96      0.92       251\n",
      "   talk.politics.mideast       0.90      0.98      0.94       231\n",
      "      talk.politics.misc       0.79      0.89      0.84       188\n",
      "      talk.religion.misc       0.93      0.44      0.60       158\n",
      "\n",
      "               micro avg       0.84      0.84      0.84      4712\n",
      "               macro avg       0.86      0.84      0.82      4712\n",
      "            weighted avg       0.86      0.84      0.82      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"the accuracy is :\",mnb.score(X_test,y_test))\n",
    "print(\"the detailed evaluation is:\",classification_report(y_test,y_predict,target_names=news.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯模型广泛应用于海量互联网文本分类任务。由于其较强的特征条件独立假设，使得模型预测所需要顾及的参数规模从幂指数量级降低为线性数量级，这也使得该模型在特征关联性较强的数据的分类任务上性能表现不佳。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
