{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征抽取：将文本数据转为向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. 33.]\n",
      " [ 0.  1.  0. 12.]\n",
      " [ 0.  0.  1. 18.]]\n",
      "['city=Dubai', 'city=London', 'city=San Fransisco', 'tem']\n"
     ]
    }
   ],
   "source": [
    "#使用DictVectorizer对使用字典存储的数据进行特征抽取和向量化\n",
    "data=[{'city':'Dubai','tem':33.},{'city':'London','tem':12.},{'city':'San Fransisco','tem':18.}]\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vec=DictVectorizer()\n",
    "print(vec.fit_transform(data).toarray())\n",
    "\n",
    "#输出各个维度的特征含义,可以看到类别特征转化为one-hot，连续数值保持不变\n",
    "print(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一些更加原始，几乎没有特殊的数据结构的数据存储，可以使用词袋法，即将不重复的词汇集合称为词表，每个训练样本都可以得到一个高维向量，\n",
    "特征数值的计算方式有两种：CountVectorizer和TfidfVectorizer\n",
    "CountVectorizer:只考虑每个词汇在该条训练样本中出现的频率\n",
    "TfidfVectorizer：不仅考虑词汇出现的频率还考虑了包含这个词汇的样本条数的个数。因此，训练样本越多，该方法越有优势，可以压制一些常用词汇对模型的干扰\n",
    "\n",
    "停用词：每个样本中都出现的常用词汇，如the,a等，通常会过滤掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news=fetch_20newsgroups(subset='all')    #下载全部2万条文本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SONG\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(news.data,news.target,test_size=0.25,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is : 0.8397707979626485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec=CountVectorizer()  #默认配置，即不去英文停用词\n",
    "\n",
    "#只使用词频统计的方式将原始训练和测试样本转化为特征向量\n",
    "X_count_train=count_vec.fit_transform(X_train)\n",
    "X_count_test=count_vec.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb_count=MultinomialNB()\n",
    "#使用朴素贝叶斯分类器\n",
    "mnb_count.fit(X_count_train,y_train)\n",
    "print(\"the accuracy is :\",mnb_count.score(X_count_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is: 0.8463497453310697\n"
     ]
    }
   ],
   "source": [
    "#使用另一种方法，在不去除停用词的情况下预测\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec=TfidfVectorizer()\n",
    "\n",
    "X_tfidf_train=tfidf_vec.fit_transform(X_train)\n",
    "X_tfidf_test=tfidf_vec.transform(X_test)\n",
    "\n",
    "mnb_tfidf=MultinomialNB()\n",
    "mnb_tfidf.fit(X_tfidf_train,y_train)\n",
    "print(\"the accuracy is:\",mnb_tfidf.score(X_tfidf_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出在都不去除停用词的情况下，第二种方法比第一种方法有所提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the performance is: 0.8637521222410866\n",
      "the performance is: 0.8826400679117148\n"
     ]
    }
   ],
   "source": [
    "#去掉停用词进行比较\n",
    "count_filter_vec=CountVectorizer(analyzer='word',stop_words='english')\n",
    "tfidf_filter_vec=TfidfVectorizer(analyzer='word',stop_words='english')\n",
    "\n",
    "X_count_filter_train=count_filter_vec.fit_transform(X_train)\n",
    "X_count_filter_test=count_filter_vec.transform(X_test)\n",
    "\n",
    "X_tfidf_filter_train=tfidf_filter_vec.fit_transform(X_train)\n",
    "X_tfidf_filter_test=tfidf_filter_vec.transform(X_test)\n",
    "\n",
    "mnb_count_filter=MultinomialNB()\n",
    "mnb_count_filter.fit(X_count_filter_train,y_train)\n",
    "print(\"the performance is:\",mnb_count_filter.score(X_count_filter_test,y_test))\n",
    "\n",
    "mnb_tfidf_filter=MultinomialNB()\n",
    "mnb_tfidf_filter.fit(X_tfidf_filter_train,y_train)\n",
    "print(\"the performance is:\",mnb_tfidf_filter.score(X_tfidf_filter_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "可以发现对停用词过滤的文本特征抽取方法比不过滤停用词的模型的综合性能高出3%-4%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
